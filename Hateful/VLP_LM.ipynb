{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import pdb\n",
    "sys.path.insert(0, '/home/jupyter/VLP/pythia')\n",
    "sys.path.insert(0, '/home/jupyter/VLP/')\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertForPreTrainingLossMask\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from vlp.loader_utils import batch_list_to_batch_tensors\n",
    "import vlp.seq2seq_loader as seq2seq_loader\n",
    "from vlp.seq2seq_loader import truncate_tokens_pair\n",
    "import PIL\n",
    "from vlp.lang_utils import language_eval\n",
    "\n",
    "from fastai.vision.all import *\n",
    "\n",
    "\n",
    "import pythia.tasks.processors as pythia_proc\n",
    "import util\n",
    "from util import *\n",
    "from vlp_processor import PreprocessVLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_recover_path = '/home/jupyter/VLP/checkpoints/vqa2_g2_lr2e-5_batch512_ft_from_s0.75_b0.25/model.19.bin'\n",
    "model_recover = torch.load(model_recover_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model():\n",
    "    cls_num_labels = 2\n",
    "    type_vocab_size = 6\n",
    "    relax_projection = 4\n",
    "    task_idx_proj = 3\n",
    "    drop_prob = .3\n",
    "\n",
    "    model = BertForPreTrainingLossMask.from_pretrained(\n",
    "                    'bert-base-cased', state_dict=model_recover, num_labels=cls_num_labels,\n",
    "                    type_vocab_size=type_vocab_size, relax_projection=relax_projection,\n",
    "                    config_path=None, task_idx=task_idx_proj,\n",
    "                    max_position_embeddings=None, \n",
    "                    label_smoothing=0,\n",
    "                    fp32_embedding=False,\n",
    "                    cache_dir='./.pretrained_model',\n",
    "                    drop_prob=drop_prob, \n",
    "                    enable_butd=True,\n",
    "                    len_vis_input=max_alen,\n",
    "                    tasks='img2txt')\n",
    "    return model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "max_alen = 100\n",
    "max_blen = 100\n",
    "max_seq_len = max_alen + max_blen + 3\n",
    "tokenizer.max_len = max_seq_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pred = 3\n",
    "mask_prob = .15\n",
    "vis_mask_prob=0\n",
    "mask_image_regions = vis_mask_prob > 0\n",
    "truncate_config={\n",
    "    'max_len_b': max_blen, 'trunc_seg': 'b', 'always_truncate_tail': True}\n",
    "region_pref = HATE_FEAT_PATH / 'feat_cls_1000/hateful_vlp_checkpoint_trainval'\n",
    "bbox_pref = HATE_FEAT_PATH / 'raw_bbox/hateful_vlp_checkpoint_trainval'\n",
    "id_digits=2\n",
    "proc=PreprocessVLP(max_pred, mask_prob,\n",
    "            list(tokenizer.vocab.keys()), tokenizer.convert_tokens_to_ids, max_seq_len,\n",
    "            truncate_config=truncate_config, mask_image_regions=mask_image_regions,\n",
    "            mode=\"bi\", len_vis_input=max_alen,\n",
    "            vis_mask_prob=vis_mask_prob, \n",
    "            region_bbox_prefix=str(bbox_pref), region_det_file_prefix=str(region_pref), id_digits=id_digits,\n",
    "             load_vqa_ann=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42953</td>\n",
       "      <td>img/42953.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>its their character not their color that matters</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23058</td>\n",
       "      <td>img/23058.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>don't be afraid to love again everyone is not like your ex</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13894</td>\n",
       "      <td>img/13894.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>putting bows on your pet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37408</td>\n",
       "      <td>img/37408.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i love everything and everybody! except for squirrels i hate squirrels</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82403</td>\n",
       "      <td>img/82403.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>everybody loves chocolate chip cookies, even hitler</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>71352</td>\n",
       "      <td>img/71352.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fighting for gay rights</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2164</td>\n",
       "      <td>img/02164.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>that feeling when you finish your homework in record time and have extra time to chill</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>3587</td>\n",
       "      <td>img/03587.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the day that shook new york city</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>47839</td>\n",
       "      <td>img/47839.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>one of the first prototypes of the atom bomb</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>34281</td>\n",
       "      <td>img/34281.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>today feels like a kinda day where i just wanna freak people out</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12540 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id            img  label  \\\n",
       "0     42953  img/42953.png    0.0   \n",
       "1     23058  img/23058.png    0.0   \n",
       "2     13894  img/13894.png    0.0   \n",
       "3     37408  img/37408.png    0.0   \n",
       "4     82403  img/82403.png    0.0   \n",
       "...     ...            ...    ...   \n",
       "1995  71352  img/71352.png    NaN   \n",
       "1996   2164  img/02164.png    NaN   \n",
       "1997   3587  img/03587.png    NaN   \n",
       "1998  47839  img/47839.png    NaN   \n",
       "1999  34281  img/34281.png    NaN   \n",
       "\n",
       "                                                                                        text  \\\n",
       "0                                           its their character not their color that matters   \n",
       "1                                 don't be afraid to love again everyone is not like your ex   \n",
       "2                                                                   putting bows on your pet   \n",
       "3                     i love everything and everybody! except for squirrels i hate squirrels   \n",
       "4                                        everybody loves chocolate chip cookies, even hitler   \n",
       "...                                                                                      ...   \n",
       "1995                                                                 fighting for gay rights   \n",
       "1996  that feeling when you finish your homework in record time and have extra time to chill   \n",
       "1997                                                        the day that shook new york city   \n",
       "1998                                            one of the first prototypes of the atom bomb   \n",
       "1999                        today feels like a kinda day where i just wanna freak people out   \n",
       "\n",
       "      is_valid  \n",
       "0        False  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  \n",
       "...        ...  \n",
       "1995      True  \n",
       "1996      True  \n",
       "1997      True  \n",
       "1998      True  \n",
       "1999      True  \n",
       "\n",
       "[12540 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PHASE_2 = Path('/home/jupyter/hate_phase2')\n",
    "train = pd.read_json(PHASE_2/'train.jsonl', lines=True)\n",
    "dev_seen = pd.read_json(PHASE_2/'dev_seen.jsonl', lines=True)\n",
    "dev_unseen = pd.read_json(PHASE_2/'dev_unseen.jsonl', lines=True)\n",
    "test_seen = pd.read_json(PHASE_2/'test_seen.jsonl', lines=True)\n",
    "test_unseen = pd.read_json(PHASE_2/'test_unseen.jsonl', lines=True)\n",
    "train['is_valid']=False\n",
    "dev_seen['is_valid']=False\n",
    "dev_unseen['is_valid']=False\n",
    "test_seen['is_valid']=True\n",
    "test_unseen['is_valid']=True\n",
    "data = pd.concat([train, dev_seen, dev_unseen,test_seen,test_unseen])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>43976</td>\n",
       "      <td>img/43976.png</td>\n",
       "      <td>when your dive instructor starts yelling in arabic</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id            img                                                text  \\\n",
       "656  43976  img/43976.png  when your dive instructor starts yelling in arabic   \n",
       "\n",
       "     is_valid  \n",
       "656      True  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_unseen[test_unseen.id==43976]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(row):\n",
    "    return 0\n",
    "def load_for_LM(row, proc, tokenizer, q=None):\n",
    "    img_id = row.id\n",
    "    text = row.text\n",
    "    if q is None: q = text\n",
    "    img_file = id_to_img_path(img_id)\n",
    "    instance = (img_file, tokenizer.tokenize(q), {'answers': ['dummy']})\n",
    "    input_ids, segment_ids, input_mask, lm_label_ids,   masked_pos, masked_weights, is_next, task_idx, conv_feats, vis_masked_pos, vis_pe, ans_labels= proc(instance)\n",
    "    \n",
    "    lm_label_ids, is_next, masked_pos,masked_weights, task_idx,vis_masked_pos = (torch.tensor(x) for x in [ lm_label_ids, is_next, masked_pos,masked_weights, task_idx,vis_masked_pos])\n",
    "    return conv_feats, vis_pe, input_ids, segment_ids, input_mask, lm_label_ids, ans_labels, is_next, masked_pos,masked_weights, task_idx,vis_masked_pos\n",
    "\n",
    "class LoadRow(Transform):\n",
    "   \n",
    "    def __init__(self,  processor, tokenizer):\n",
    "        self.proc = processor\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def encodes(self, x, **kwargs):\n",
    "        return load_for_LM(x, self.proc, self.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DataBlock(blocks = (TransformBlock, CategoryBlock), \n",
    "               get_x = LoadRow(proc, tokenizer), \n",
    "              # get_y=get_y,splitter = RandomSplitter(valid_pct=0.0052))\n",
    "               get_y=get_y,  splitter=ColSplitter('is_valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9540, 3000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = db.dataloaders(data,bs=64)\n",
    "len(dls.train_ds), len(dls.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_loss(x,y): return x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting the new dropout rate! 0.3\n"
     ]
    }
   ],
   "source": [
    "learn = Learner(dls, new_model(),loss_func=fake_loss).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.116813</td>\n",
       "      <td>3.617211</td>\n",
       "      <td>05:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.240519</td>\n",
       "      <td>3.286396</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.811213</td>\n",
       "      <td>3.003486</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.505065</td>\n",
       "      <td>2.842045</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.303301</td>\n",
       "      <td>2.789608</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.160961</td>\n",
       "      <td>2.776133</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.951640</td>\n",
       "      <td>2.651431</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.833458</td>\n",
       "      <td>2.599370</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.703713</td>\n",
       "      <td>2.623725</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.590730</td>\n",
       "      <td>2.539920</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.503605</td>\n",
       "      <td>2.533649</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.348879</td>\n",
       "      <td>2.516851</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.295957</td>\n",
       "      <td>2.452550</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.288617</td>\n",
       "      <td>2.492181</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.218068</td>\n",
       "      <td>2.510317</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.149964</td>\n",
       "      <td>2.440837</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.121191</td>\n",
       "      <td>2.400260</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.128564</td>\n",
       "      <td>2.427049</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.126796</td>\n",
       "      <td>2.405646</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.103676</td>\n",
       "      <td>2.340899</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(20 , lr_max = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#was 2.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/trained_30drop.pth')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learn.save('trained_lm20drop')\n",
    "#learn.save('lm_token')\n",
    "#learn.load('lm_token')\n",
    "learn.save('trained_30drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7fae54ec8a90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('trained_long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HateStem(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, vlp):\n",
    "        super(HateStem, self).__init__()\n",
    "        self.vis_embed = vlp.vis_embed #Linear->ReLU->Linear->ReLU->dropout\n",
    "        self.vis_pe_embed = vlp.vis_pe_embed #Linear->ReLU->dropout\n",
    "        self.bert = vlp.bert # pytorch_pretrained_bert.modeling.BertModel\n",
    "        self.len_vis_input = vlp.len_vis_input\n",
    "        \n",
    "    \n",
    "    def forward(self, vis_feats, vis_pe, input_ids, token_type_ids=None, attention_mask=None):\n",
    "        vis_feats = self.vis_embed(vis_feats) # image region features\n",
    "        vis_pe = self.vis_pe_embed(vis_pe) # image region positional encodings\n",
    "\n",
    "        sequence_output, pooled_output = self.bert(vis_feats, vis_pe, input_ids, token_type_ids,\n",
    "            attention_mask, output_all_encoded_layers=False, len_vis_input=self.len_vis_input)\n",
    "        #print(sequence_output.shape, pooled_output.shape)\n",
    "        vqa2_embed = sequence_output[:, 0]*sequence_output[:, self.len_vis_input+1]\n",
    "        return vqa2_embed\n",
    "        #return sequence_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_stem = HateStem(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:262] . unexpected pos 181492864 vs 181492752",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/vlp/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/vlp/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mbuf_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-41d9fa19926f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_stem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'checkpoints/lm_stem30drop_p2.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/vlp/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/vlp/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:262] . unexpected pos 181492864 vs 181492752"
     ]
    }
   ],
   "source": [
    "torch.save(lm_stem, 'checkpoints/lm_stem30drop_p2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlp",
   "language": "python",
   "name": "vlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
