{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import pdb\n",
    "sys.path.insert(0, '/home/jupyter/VLP/pythia')\n",
    "sys.path.insert(0, '/home/jupyter/VLP/')\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertForPreTrainingLossMask\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from vlp.loader_utils import batch_list_to_batch_tensors\n",
    "import vlp.seq2seq_loader as seq2seq_loader\n",
    "from vlp.seq2seq_loader import truncate_tokens_pair\n",
    "import PIL\n",
    "from vlp.lang_utils import language_eval\n",
    "\n",
    "from fastai.vision.all import *\n",
    "\n",
    "\n",
    "import pythia.tasks.processors as pythia_proc\n",
    "import util\n",
    "from util import *\n",
    "from vlp_processor import PreprocessVLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_recover_path = '/home/jupyter/VLP/checkpoints/vqa2_g2_lr2e-5_batch512_ft_from_s0.75_b0.25/model.19.bin'\n",
    "model_recover = torch.load(model_recover_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model():\n",
    "    cls_num_labels = 2\n",
    "    type_vocab_size = 6\n",
    "    relax_projection = 4\n",
    "    task_idx_proj = 3\n",
    "    drop_prob = .25\n",
    "\n",
    "    model = BertForPreTrainingLossMask.from_pretrained(\n",
    "                    'bert-base-cased', state_dict=model_recover, num_labels=cls_num_labels,\n",
    "                    type_vocab_size=type_vocab_size, relax_projection=relax_projection,\n",
    "                    config_path=None, task_idx=task_idx_proj,\n",
    "                    max_position_embeddings=None, \n",
    "                    label_smoothing=0,\n",
    "                    fp32_embedding=False,\n",
    "                    cache_dir='./.pretrained_model',\n",
    "                    drop_prob=drop_prob, \n",
    "                    enable_butd=True,\n",
    "                    len_vis_input=max_alen,\n",
    "                    tasks='img2txt')\n",
    "    return model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "max_alen = 100\n",
    "max_blen = 100\n",
    "max_seq_len = max_alen + max_blen + 3\n",
    "tokenizer.max_len = max_seq_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pred = 3\n",
    "mask_prob = .15\n",
    "vis_mask_prob=0\n",
    "mask_image_regions = vis_mask_prob > 0\n",
    "truncate_config={\n",
    "    'max_len_b': max_blen, 'trunc_seg': 'b', 'always_truncate_tail': True}\n",
    "region_pref = HATE_FEAT_PATH / 'feat_cls_1000/hateful_vlp_checkpoint_trainval'\n",
    "bbox_pref = HATE_FEAT_PATH / 'raw_bbox/hateful_vlp_checkpoint_trainval'\n",
    "id_digits=2\n",
    "proc=PreprocessVLP(max_pred, mask_prob,\n",
    "            list(tokenizer.vocab.keys()), tokenizer.convert_tokens_to_ids, max_seq_len,\n",
    "            truncate_config=truncate_config, mask_image_regions=mask_image_regions,\n",
    "            mode=\"bi\", len_vis_input=max_alen,\n",
    "            vis_mask_prob=vis_mask_prob, \n",
    "            region_bbox_prefix=str(bbox_pref), region_det_file_prefix=str(region_pref), id_digits=id_digits,\n",
    "             load_vqa_ann=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42953</td>\n",
       "      <td>img/42953.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>its their character not their color that matters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23058</td>\n",
       "      <td>img/23058.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>don't be afraid to love again everyone is not like your ex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13894</td>\n",
       "      <td>img/13894.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>putting bows on your pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37408</td>\n",
       "      <td>img/37408.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i love everything and everybody! except for squirrels i hate squirrels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82403</td>\n",
       "      <td>img/82403.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>everybody loves chocolate chip cookies, even hitler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>71352</td>\n",
       "      <td>img/71352.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fighting for gay rights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2164</td>\n",
       "      <td>img/02164.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>that feeling when you finish your homework in record time and have extra time to chill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>3587</td>\n",
       "      <td>img/03587.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the day that shook new york city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>47839</td>\n",
       "      <td>img/47839.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>one of the first prototypes of the atom bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>34281</td>\n",
       "      <td>img/34281.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>today feels like a kinda day where i just wanna freak people out</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12540 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id            img  label  \\\n",
       "0     42953  img/42953.png    0.0   \n",
       "1     23058  img/23058.png    0.0   \n",
       "2     13894  img/13894.png    0.0   \n",
       "3     37408  img/37408.png    0.0   \n",
       "4     82403  img/82403.png    0.0   \n",
       "...     ...            ...    ...   \n",
       "1995  71352  img/71352.png    NaN   \n",
       "1996   2164  img/02164.png    NaN   \n",
       "1997   3587  img/03587.png    NaN   \n",
       "1998  47839  img/47839.png    NaN   \n",
       "1999  34281  img/34281.png    NaN   \n",
       "\n",
       "                                                                                        text  \n",
       "0                                           its their character not their color that matters  \n",
       "1                                 don't be afraid to love again everyone is not like your ex  \n",
       "2                                                                   putting bows on your pet  \n",
       "3                     i love everything and everybody! except for squirrels i hate squirrels  \n",
       "4                                        everybody loves chocolate chip cookies, even hitler  \n",
       "...                                                                                      ...  \n",
       "1995                                                                 fighting for gay rights  \n",
       "1996  that feeling when you finish your homework in record time and have extra time to chill  \n",
       "1997                                                        the day that shook new york city  \n",
       "1998                                            one of the first prototypes of the atom bomb  \n",
       "1999                        today feels like a kinda day where i just wanna freak people out  \n",
       "\n",
       "[12540 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PHASE_2 = Path('/home/jupyter/hate_phase2')\n",
    "train = pd.read_json(PHASE_2/'train.jsonl', lines=True)\n",
    "dev_seen = pd.read_json(PHASE_2/'dev_seen.jsonl', lines=True)\n",
    "dev_unseen = pd.read_json(PHASE_2/'dev_unseen.jsonl', lines=True)\n",
    "test_seen = pd.read_json(PHASE_2/'test_seen.jsonl', lines=True)\n",
    "test_unseen = pd.read_json(PHASE_2/'test_unseen.jsonl', lines=True)\n",
    "data = pd.concat([train, dev_seen, dev_unseen,test_seen,test_unseen])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>43976</td>\n",
       "      <td>img/43976.png</td>\n",
       "      <td>when your dive instructor starts yelling in arabic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id            img                                                text\n",
       "656  43976  img/43976.png  when your dive instructor starts yelling in arabic"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_unseen[test_unseen.id==43976]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(row):\n",
    "    return 0\n",
    "def load_for_LM(row, proc, tokenizer, q=None):\n",
    "    img_id = row.id\n",
    "    text = row.text\n",
    "    if q is None: q = text\n",
    "    img_file = id_to_img_path(img_id)\n",
    "    instance = (img_file, tokenizer.tokenize(q), {'answers': ['dummy']})\n",
    "    input_ids, segment_ids, input_mask, lm_label_ids,   masked_pos, masked_weights, is_next, task_idx, conv_feats, vis_masked_pos, vis_pe, ans_labels= proc(instance)\n",
    "    \n",
    "    lm_label_ids, is_next, masked_pos,masked_weights, task_idx,vis_masked_pos = (torch.tensor(x) for x in [ lm_label_ids, is_next, masked_pos,masked_weights, task_idx,vis_masked_pos])\n",
    "    return conv_feats, vis_pe, input_ids, segment_ids, input_mask, lm_label_ids, ans_labels, is_next, masked_pos,masked_weights, task_idx,vis_masked_pos\n",
    "\n",
    "class LoadRow(Transform):\n",
    "   \n",
    "    def __init__(self,  processor, tokenizer):\n",
    "        self.proc = processor\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def encodes(self, x, **kwargs):\n",
    "        return load_for_LM(x, self.proc, self.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DataBlock(blocks = (TransformBlock, CategoryBlock), \n",
    "               get_x = LoadRow(proc, tokenizer), \n",
    "               get_y=get_y,splitter = RandomSplitter(valid_pct=0.0052))\n",
    "              # get_y=get_y,splitter = RandomSplitter(valid_pct=0.10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12475, 65)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = db.dataloaders(data,bs=64)\n",
    "len(dls.train_ds), len(dls.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dls.one_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([64, 100, 2048]),\n",
       " torch.Size([64, 100, 1607]),\n",
       " torch.Size([64, 203]),\n",
       " torch.Size([64, 203]),\n",
       " torch.Size([64, 203, 203]),\n",
       " torch.Size([64, 3]),\n",
       " torch.Size([64, 1]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64, 3]),\n",
       " torch.Size([64, 3]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64, 0])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in batch[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_loss(x,y): return x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting the new dropout rate! 0.25\n"
     ]
    }
   ],
   "source": [
    "learn = Learner(dls, new_model(),loss_func=fake_loss).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.310086</td>\n",
       "      <td>3.695831</td>\n",
       "      <td>05:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.523596</td>\n",
       "      <td>3.233771</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.174065</td>\n",
       "      <td>2.787822</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.890528</td>\n",
       "      <td>2.189437</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.695524</td>\n",
       "      <td>2.346471</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.515508</td>\n",
       "      <td>2.382189</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.421152</td>\n",
       "      <td>1.829092</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.274048</td>\n",
       "      <td>1.774992</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.197291</td>\n",
       "      <td>2.352219</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.204267</td>\n",
       "      <td>1.915022</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10 , lr_max = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.163623</td>\n",
       "      <td>1.923067</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.138697</td>\n",
       "      <td>1.836306</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.149936</td>\n",
       "      <td>2.005157</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.126229</td>\n",
       "      <td>1.723796</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.040904</td>\n",
       "      <td>1.980285</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.008515</td>\n",
       "      <td>1.923516</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.919147</td>\n",
       "      <td>1.865721</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.853806</td>\n",
       "      <td>1.626781</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.829888</td>\n",
       "      <td>1.524760</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.776754</td>\n",
       "      <td>2.052647</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.691048</td>\n",
       "      <td>1.448932</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.691802</td>\n",
       "      <td>1.942143</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.675653</td>\n",
       "      <td>1.835146</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.644276</td>\n",
       "      <td>2.125239</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.646133</td>\n",
       "      <td>1.649578</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(15 , lr_max = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#was 2.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/trained_long.pth')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learn.save('trained_lm20drop')\n",
    "#learn.save('lm_token')\n",
    "#learn.load('lm_token')\n",
    "learn.save('trained_long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7fae54ec8a90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('trained_long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.669330</td>\n",
       "      <td>1.141289</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.670578</td>\n",
       "      <td>1.276379</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.616257</td>\n",
       "      <td>1.280647</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.696579</td>\n",
       "      <td>1.427132</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.650644</td>\n",
       "      <td>1.352159</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.604179</td>\n",
       "      <td>1.460073</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.611321</td>\n",
       "      <td>1.464201</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.508295</td>\n",
       "      <td>1.223068</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.476136</td>\n",
       "      <td>1.502977</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.452808</td>\n",
       "      <td>1.151719</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.391712</td>\n",
       "      <td>1.766586</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.378368</td>\n",
       "      <td>1.458822</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.395479</td>\n",
       "      <td>1.605072</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.368446</td>\n",
       "      <td>1.559295</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.338125</td>\n",
       "      <td>1.076545</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(15 , lr_max = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.344204</td>\n",
       "      <td>1.632730</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.355910</td>\n",
       "      <td>1.482232</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.319746</td>\n",
       "      <td>1.831060</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.392142</td>\n",
       "      <td>1.821571</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.341137</td>\n",
       "      <td>1.299373</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.352200</td>\n",
       "      <td>1.271740</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.299891</td>\n",
       "      <td>1.297472</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.278458</td>\n",
       "      <td>0.995830</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.216862</td>\n",
       "      <td>1.630893</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.168598</td>\n",
       "      <td>1.138420</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.167097</td>\n",
       "      <td>1.558407</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.151749</td>\n",
       "      <td>1.111852</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.186890</td>\n",
       "      <td>1.376161</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.133959</td>\n",
       "      <td>1.213601</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.118507</td>\n",
       "      <td>1.305831</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(15 , lr_max = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HateStem(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, vlp):\n",
    "        super(HateStem, self).__init__()\n",
    "        self.vis_embed = vlp.vis_embed #Linear->ReLU->Linear->ReLU->dropout\n",
    "        self.vis_pe_embed = vlp.vis_pe_embed #Linear->ReLU->dropout\n",
    "        self.bert = vlp.bert # pytorch_pretrained_bert.modeling.BertModel\n",
    "        self.len_vis_input = vlp.len_vis_input\n",
    "        \n",
    "    \n",
    "    def forward(self, vis_feats, vis_pe, input_ids, token_type_ids=None, attention_mask=None):\n",
    "        vis_feats = self.vis_embed(vis_feats) # image region features\n",
    "        vis_pe = self.vis_pe_embed(vis_pe) # image region positional encodings\n",
    "\n",
    "        sequence_output, pooled_output = self.bert(vis_feats, vis_pe, input_ids, token_type_ids,\n",
    "            attention_mask, output_all_encoded_layers=False, len_vis_input=self.len_vis_input)\n",
    "        #print(sequence_output.shape, pooled_output.shape)\n",
    "        vqa2_embed = sequence_output[:, 0]*sequence_output[:, self.len_vis_input+1]\n",
    "        return vqa2_embed\n",
    "        #return sequence_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_stem = HateStem(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lm_stem, 'checkpoints/lm_stem_long.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlp",
   "language": "python",
   "name": "vlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
