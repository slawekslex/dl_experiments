{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import pdb\n",
    "sys.path.insert(0, '/home/jupyter/VLP/pythia')\n",
    "sys.path.insert(0, '/home/jupyter/VLP/')\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertForPreTrainingLossMask\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from vlp.loader_utils import batch_list_to_batch_tensors\n",
    "import vlp.seq2seq_loader as seq2seq_loader\n",
    "import PIL\n",
    "from vlp.lang_utils import language_eval\n",
    "\n",
    "from fastai.vision.all import *\n",
    "\n",
    "from vlp_processor import PreprocessVLP\n",
    "import pythia.tasks.processors as pythia_proc\n",
    "\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgDummy(dict):\n",
    "    def __getattr__(self, attr):\n",
    "        return self[attr]\n",
    "args = ArgDummy()\n",
    "DATA_ROOT = '/mnt/ssd/data'\n",
    "HATE_FEAT_PATH = Path('/home/jupyter/hateful_features/region_feat_gvd_wo_bgd')\n",
    "\n",
    "args['bert_model'] = 'bert-base-cased' #Bert pre-trained model selected\n",
    "args['seed'] = 123 #random seed for initialization\n",
    "args['len_vis_input'] = 100\n",
    "args['max_tgt_length'] = 100#20 #maximum length of target sequence\n",
    "args['region_det_file_prefix'] = 'feat_cls_1000/coco_detection_vg_100dets_gvd_checkpoint_trainval'\n",
    "args['output_dir'] ='tmp'\n",
    "args['drop_prob'] = 0.1\n",
    "args['model_recover_path'] = './checkpoints/vqa2_g2_lr2e-5_batch512_ft_from_s0.75_b0.25/model.19.bin'\n",
    "args['image_root'] = f'{DATA_ROOT}/flickr30k/region_feat_gvd_wo_bgd/'\n",
    "args['region_bbox_file'] =f'{DATA_ROOT}/flickr30k/region_feat_gvd_wo_bgd/flickr30k_detection_vg_thresh0.2_feat_gvd_checkpoint_trainvaltest.h5'\n",
    "args['do_lower_case'] = True\n",
    "args.region_bbox_file = os.path.join(args.image_root, args.region_bbox_file)\n",
    "args.region_det_file_prefix = os.path.join(args.image_root, args.region_det_file_prefix)\n",
    "args.max_seq_length = args.max_tgt_length + args.len_vis_input + 3 # +3 for 2x[SEP] and [CLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# fix random seed\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "tokenizer = BertTokenizer.from_pretrained(args.bert_model, do_lower_case=args.do_lower_case)\n",
    "tokenizer.max_len = args.max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HateStem(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, vlp):\n",
    "        super(HateStem, self).__init__()\n",
    "        self.vis_embed = vlp.vis_embed #Linear->ReLU->Linear->ReLU->dropout\n",
    "        self.vis_pe_embed = vlp.vis_pe_embed #Linear->ReLU->dropout\n",
    "        self.bert = vlp.bert # pytorch_pretrained_bert.modeling.BertModel\n",
    "        self.len_vis_input = vlp.len_vis_input\n",
    "        \n",
    "    \n",
    "    def forward(self, vis_feats, vis_pe, input_ids, token_type_ids=None, attention_mask=None):\n",
    "        vis_feats = self.vis_embed(vis_feats) # image region features\n",
    "        vis_pe = self.vis_pe_embed(vis_pe) # image region positional encodings\n",
    "\n",
    "        sequence_output, pooled_output = self.bert(vis_feats, vis_pe, input_ids, token_type_ids,\n",
    "            attention_mask, output_all_encoded_layers=False, len_vis_input=self.len_vis_input)\n",
    "        #print(sequence_output.shape, pooled_output.shape)\n",
    "        vqa2_embed = sequence_output[:, 0]*sequence_output[:, self.len_vis_input+1]\n",
    "        return vqa2_embed\n",
    "        #return sequence_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_head(nf, n_out, lin_ftrs=None, ps=0.5, bn_final=False, lin_first=False, ):\n",
    "    \"Model head that takes `nf` features, runs through `lin_ftrs`, and out `n_out` classes.\"\n",
    "    lin_ftrs = [nf, 512, n_out] if lin_ftrs is None else [nf] + lin_ftrs + [n_out]\n",
    "    ps = L(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    layers = []\n",
    "    layers = [Flatten()]\n",
    "    if lin_first: layers.append(nn.Dropout(ps.pop(0)))\n",
    "    for ni,no,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], ps, actns):\n",
    "        layers += LinBnDrop(ni, no, bn=True, p=p, act=actn, lin_first=lin_first)\n",
    "    if lin_first: layers.append(nn.Linear(lin_ftrs[-2], n_out))\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HateClassifier(torch.nn.Module):\n",
    "     def __init__(self, stem):\n",
    "        super(HateClassifier, self).__init__()\n",
    "        self.stem = stem\n",
    "        self.classifier = create_head(768,2, ps=.5)\n",
    "     #def forward(self, id, vis_feats, vis_pe, input_ids, token_type_ids, attention_mask):  \n",
    "     def forward(self, params):  \n",
    "        id, vis_feats, vis_pe, input_ids, token_type_ids, attention_mask = params\n",
    "        embs = self.stem(vis_feats, vis_pe, input_ids, token_type_ids, attention_mask)\n",
    "        return self.classifier(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model():\n",
    "    hate_stem = torch.load('checkpoints/lm_stem20drop.pth')\n",
    "    \n",
    "    return  HateClassifier(hate_stem).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42953</td>\n",
       "      <td>img/42953.png</td>\n",
       "      <td>1</td>\n",
       "      <td>its their character not their color that matters</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23058</td>\n",
       "      <td>img/23058.png</td>\n",
       "      <td>1</td>\n",
       "      <td>don't be afraid to love again everyone is not like your ex</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13894</td>\n",
       "      <td>img/13894.png</td>\n",
       "      <td>1</td>\n",
       "      <td>putting bows on your pet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            img  label  \\\n",
       "0  42953  img/42953.png      1   \n",
       "1  23058  img/23058.png      1   \n",
       "2  13894  img/13894.png      1   \n",
       "\n",
       "                                                         text is_valid  \n",
       "0            its their character not their color that matters    False  \n",
       "1  don't be afraid to love again everyone is not like your ex    False  \n",
       "2                                    putting bows on your pet    False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path =  Path('/home/jupyter/VLP')\n",
    "data =pd.read_csv(path/'captioned.csv')\n",
    "data =data.drop(['caption', 'tex_cap'], axis=1)\n",
    "data['label'] = 1\n",
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data[:8000])\n",
    "df_valid = pd.DataFrame(data[8000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['is_valid'] = False\n",
    "df_valid['is_valid'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9534, 9389, 9406, 9346, 9122])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ids = df_valid.index.tolist()\n",
    "valid_wrong = np.random.choice(valid_ids,len(valid_ids)//2)\n",
    "valid_wrong[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9980, 8885, 9719, 9071, 9125])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled = np.random.permutation(valid_wrong)\n",
    "shuffled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"my name is osama bin laden and this is jackass\"',\n",
       " 'and then i asked mom, can we go play?',\n",
       " 'all was well in new york until the fire nation attacked',\n",
       " 'when you got a warrant out for your arrest & you on the run.....',\n",
       " 'that look when you high as fuck on dem chromosomes']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuf_texts = df_valid.loc[shuffled]['text'].tolist()\n",
    "shuf_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.loc[valid_wrong, 'text']= shuf_texts\n",
    "df_valid.loc[valid_wrong, 'label'] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8000</th>\n",
       "      <td>43895</td>\n",
       "      <td>img/43895.png</td>\n",
       "      <td>1</td>\n",
       "      <td>from here i will see muslims fuck up europe, attack innocent people &amp; europeans waking up</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8001</th>\n",
       "      <td>62537</td>\n",
       "      <td>img/62537.png</td>\n",
       "      <td>0</td>\n",
       "      <td>what do they have in common? you enjoy pushing them down the stairs</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8002</th>\n",
       "      <td>76950</td>\n",
       "      <td>img/76950.png</td>\n",
       "      <td>0</td>\n",
       "      <td>if you ever feel down just remember there are people that are down their whole life</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8003</th>\n",
       "      <td>16374</td>\n",
       "      <td>img/16374.png</td>\n",
       "      <td>0</td>\n",
       "      <td>the islamic sacred book, believed to be the word of god as dictated to muhammad</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8004</th>\n",
       "      <td>58732</td>\n",
       "      <td>img/58732.png</td>\n",
       "      <td>1</td>\n",
       "      <td>meanwhile at the isis strip club</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3869</td>\n",
       "      <td>img/03869.png</td>\n",
       "      <td>0</td>\n",
       "      <td>she represents the new wave of democrats</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>23817</td>\n",
       "      <td>img/23817.png</td>\n",
       "      <td>0</td>\n",
       "      <td>back in my day there were only two genders male and not male</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>56280</td>\n",
       "      <td>img/56280.png</td>\n",
       "      <td>1</td>\n",
       "      <td>little miss muffet sat on her tuffet</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>29384</td>\n",
       "      <td>img/29384.png</td>\n",
       "      <td>0</td>\n",
       "      <td>i'm deporting all mexicans!!! except the ones in baldwin park you fuckers are crazy!!!</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>34127</td>\n",
       "      <td>img/34127.png</td>\n",
       "      <td>1</td>\n",
       "      <td>that feeling when you win a fifa game after being 3 goals behind</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id            img  label  \\\n",
       "8000  43895  img/43895.png      1   \n",
       "8001  62537  img/62537.png      0   \n",
       "8002  76950  img/76950.png      0   \n",
       "8003  16374  img/16374.png      0   \n",
       "8004  58732  img/58732.png      1   \n",
       "...     ...            ...    ...   \n",
       "9995   3869  img/03869.png      0   \n",
       "9996  23817  img/23817.png      0   \n",
       "9997  56280  img/56280.png      1   \n",
       "9998  29384  img/29384.png      0   \n",
       "9999  34127  img/34127.png      1   \n",
       "\n",
       "                                                                                           text  \\\n",
       "8000  from here i will see muslims fuck up europe, attack innocent people & europeans waking up   \n",
       "8001                        what do they have in common? you enjoy pushing them down the stairs   \n",
       "8002        if you ever feel down just remember there are people that are down their whole life   \n",
       "8003            the islamic sacred book, believed to be the word of god as dictated to muhammad   \n",
       "8004                                                           meanwhile at the isis strip club   \n",
       "...                                                                                         ...   \n",
       "9995                                                   she represents the new wave of democrats   \n",
       "9996                               back in my day there were only two genders male and not male   \n",
       "9997                                                       little miss muffet sat on her tuffet   \n",
       "9998     i'm deporting all mexicans!!! except the ones in baldwin park you fuckers are crazy!!!   \n",
       "9999                           that feeling when you win a fifa game after being 3 goals behind   \n",
       "\n",
       "      is_valid  \n",
       "8000      True  \n",
       "8001      True  \n",
       "8002      True  \n",
       "8003      True  \n",
       "8004      True  \n",
       "...        ...  \n",
       "9995      True  \n",
       "9996      True  \n",
       "9997      True  \n",
       "9998      True  \n",
       "9999      True  \n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42953</td>\n",
       "      <td>img/42953.png</td>\n",
       "      <td>1</td>\n",
       "      <td>its their character not their color that matters</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23058</td>\n",
       "      <td>img/23058.png</td>\n",
       "      <td>1</td>\n",
       "      <td>don't be afraid to love again everyone is not like your ex</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13894</td>\n",
       "      <td>img/13894.png</td>\n",
       "      <td>1</td>\n",
       "      <td>putting bows on your pet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37408</td>\n",
       "      <td>img/37408.png</td>\n",
       "      <td>1</td>\n",
       "      <td>i love everything and everybody! except for squirrels i hate squirrels</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82403</td>\n",
       "      <td>img/82403.png</td>\n",
       "      <td>1</td>\n",
       "      <td>everybody loves chocolate chip cookies, even hitler</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3869</td>\n",
       "      <td>img/03869.png</td>\n",
       "      <td>0</td>\n",
       "      <td>she represents the new wave of democrats</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>23817</td>\n",
       "      <td>img/23817.png</td>\n",
       "      <td>0</td>\n",
       "      <td>back in my day there were only two genders male and not male</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>56280</td>\n",
       "      <td>img/56280.png</td>\n",
       "      <td>1</td>\n",
       "      <td>little miss muffet sat on her tuffet</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>29384</td>\n",
       "      <td>img/29384.png</td>\n",
       "      <td>0</td>\n",
       "      <td>i'm deporting all mexicans!!! except the ones in baldwin park you fuckers are crazy!!!</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>34127</td>\n",
       "      <td>img/34127.png</td>\n",
       "      <td>1</td>\n",
       "      <td>that feeling when you win a fifa game after being 3 goals behind</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id            img  label  \\\n",
       "0     42953  img/42953.png      1   \n",
       "1     23058  img/23058.png      1   \n",
       "2     13894  img/13894.png      1   \n",
       "3     37408  img/37408.png      1   \n",
       "4     82403  img/82403.png      1   \n",
       "...     ...            ...    ...   \n",
       "9995   3869  img/03869.png      0   \n",
       "9996  23817  img/23817.png      0   \n",
       "9997  56280  img/56280.png      1   \n",
       "9998  29384  img/29384.png      0   \n",
       "9999  34127  img/34127.png      1   \n",
       "\n",
       "                                                                                        text  \\\n",
       "0                                           its their character not their color that matters   \n",
       "1                                 don't be afraid to love again everyone is not like your ex   \n",
       "2                                                                   putting bows on your pet   \n",
       "3                     i love everything and everybody! except for squirrels i hate squirrels   \n",
       "4                                        everybody loves chocolate chip cookies, even hitler   \n",
       "...                                                                                      ...   \n",
       "9995                                                she represents the new wave of democrats   \n",
       "9996                            back in my day there were only two genders male and not male   \n",
       "9997                                                    little miss muffet sat on her tuffet   \n",
       "9998  i'm deporting all mexicans!!! except the ones in baldwin park you fuckers are crazy!!!   \n",
       "9999                        that feeling when you win a fifa game after being 3 goals behind   \n",
       "\n",
       "      is_valid  \n",
       "0        False  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  \n",
       "...        ...  \n",
       "9995      True  \n",
       "9996      True  \n",
       "9997      True  \n",
       "9998      True  \n",
       "9999      True  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([df_train, df_valid])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(idx, proc, q=None):\n",
    "    return load_from_row(data.iloc[idx],proc, tokenizer, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_pref = HATE_FEAT_PATH / 'feat_cls_1000/hateful_vlp_checkpoint_trainval'\n",
    "bbox_pref = HATE_FEAT_PATH / 'raw_bbox/hateful_vlp_checkpoint_trainval'\n",
    "id_digits=2\n",
    "\n",
    "truncate_config={\n",
    "    'max_len_b': args.max_tgt_length, 'trunc_seg': 'b', 'always_truncate_tail': True}\n",
    "\n",
    "max_masked = 10\n",
    "mask_prob = .20\n",
    "mask_img=True\n",
    "vis_mask_prob = .20\n",
    "train_proc = PreprocessVLP(max_masked, mask_prob,\n",
    "    list(tokenizer.vocab.keys()), tokenizer.convert_tokens_to_ids, args.max_seq_length,\n",
    "    truncate_config=truncate_config,mask_image_regions=mask_img, vis_mask_prob=vis_mask_prob,\n",
    "    mode=\"bi\", len_vis_input=args.len_vis_input, \n",
    "    region_bbox_prefix=str(bbox_pref), region_det_file_prefix=str(region_pref), id_digits=id_digits,\n",
    "    load_vqa_ann=True)\n",
    "\n",
    "val_proc = PreprocessVLP(0, 0,\n",
    "    list(tokenizer.vocab.keys()), tokenizer.convert_tokens_to_ids, args.max_seq_length,\n",
    "    truncate_config=truncate_config,mask_image_regions=False, vis_mask_prob=0,\n",
    "    mode=\"bi\", len_vis_input=args.len_vis_input, \n",
    "    region_bbox_prefix=str(bbox_pref), region_det_file_prefix=str(region_pref), id_digits=id_digits,\n",
    "    load_vqa_ann=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@typedispatch\n",
    "def show_batch(x:VLPInput, y, samples, ctxs=None, max_n=10, nrows=None, ncols=None, figsize=None, **kwargs):\n",
    "    if ctxs is None: ctxs = get_grid(min(len(samples), max_n), nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "    ctxs = show_batch[object](x, y, samples, ctxs=ctxs, max_n=max_n, **kwargs)\n",
    "    return ctxs\n",
    "\n",
    "@typedispatch\n",
    "def show_results(x:VLPInput, y:TensorCategory, samples, outs, ctxs=None, max_n=10, nrows=None, ncols=None, figsize=None, **kwargs):\n",
    "    if ctxs is None: ctxs = get_grid(min(len(samples), max_n), nrows=nrows, ncols=ncols, add_vert=1, figsize=figsize)\n",
    "    for i in range(2):\n",
    "        ctxs = [b.show(ctx=c, **kwargs) for b,c,_ in zip(samples.itemgot(i),ctxs,range(max_n))]\n",
    "    ctxs = [r.show(ctx=c, color='green' if b==r else 'red', **kwargs)\n",
    "            for b,r,c,_ in zip(samples.itemgot(1),outs.itemgot(0),ctxs,range(max_n))]\n",
    "    return ctxs\n",
    "\n",
    "\n",
    "@typedispatch\n",
    "def plot_top_losses(x: VLPInput, y:TensorCategory, samples, outs, raws, losses, nrows=None, ncols=None, figsize=None, **kwargs):\n",
    "    axs = get_grid(len(samples), nrows=nrows, ncols=ncols, add_vert=1, figsize=figsize, title='Prediction/Actual/Loss/Probability')\n",
    "    for ax,s,o,r,l in zip(axs, samples, outs, raws, losses):\n",
    "        s[0].show(ctx=ax, **kwargs)\n",
    "        ax.set_title(f'{o}/{s[1]} / {l.item():.2f} / {r.max().item():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadRow(Transform):\n",
    "    \n",
    "    def __init__(self,processor, tokenizer, random_text=False, data = None):\n",
    "        self.proc = processor\n",
    "        self.tokenizer = tokenizer\n",
    "        self.random_text = random_text\n",
    "        self.data = data\n",
    "    def encodes(self, x):\n",
    "        if self.random_text and random.choice((True, False)):\n",
    "            x = pd.Series(x)\n",
    "            altloc = random.randint(0, len(self.data)-1)\n",
    "            alttext = self.data.iloc[altloc].text\n",
    "            x['text'] = alttext\n",
    "            x['label'] = 0\n",
    "        return load_from_row(x, self.proc, self.tokenizer), x.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load = LoadRow(train_proc, tokenizer, True, df_train)\n",
    "valid_load = LoadRow(val_proc, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tl = TfmdLists(df_train, train_load)\n",
    "valid_tl = TfmdLists(df_valid, valid_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dsets(train_tl, valid_tl,bs=40, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@patch_to(VLPInput)\n",
    "def show(self, ctx, **kwargs):\n",
    "    id = self[0].item()\n",
    "    tit = id_to_text(id, data)\n",
    "    ctx.text(0,0,tit,ha='left', wrap=True)\n",
    "    ctx = show_image(PILImage.create(id_to_img_path(id)), ctx=ctx)\n",
    "    return ctx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dls.show_batch(dls.valid.one_batch(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vlp_splitter(model):\n",
    "    return L(params(model.stem.vis_embed) + params(model.stem.vis_pe_embed), \n",
    "            params(model.stem.bert),\n",
    "            params(model.classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = new_model()\n",
    "learn = Learner(dls, model,metrics=[accuracy, RocAucBinary()], splitter=vlp_splitter, loss_func = nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.771432</td>\n",
       "      <td>0.685338</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.564231</td>\n",
       "      <td>02:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.708316</td>\n",
       "      <td>0.642906</td>\n",
       "      <td>0.619000</td>\n",
       "      <td>0.647331</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.669607</td>\n",
       "      <td>0.635611</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.703256</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.595504</td>\n",
       "      <td>0.569623</td>\n",
       "      <td>0.701500</td>\n",
       "      <td>0.746513</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.550967</td>\n",
       "      <td>0.626213</td>\n",
       "      <td>0.695500</td>\n",
       "      <td>0.775270</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.539172</td>\n",
       "      <td>0.948392</td>\n",
       "      <td>0.592500</td>\n",
       "      <td>0.736549</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.509670</td>\n",
       "      <td>0.717090</td>\n",
       "      <td>0.701500</td>\n",
       "      <td>0.805613</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.472479</td>\n",
       "      <td>0.671963</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.794498</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.462133</td>\n",
       "      <td>0.819404</td>\n",
       "      <td>0.637000</td>\n",
       "      <td>0.773235</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.449377</td>\n",
       "      <td>0.825591</td>\n",
       "      <td>0.639500</td>\n",
       "      <td>0.780354</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.431898</td>\n",
       "      <td>0.832285</td>\n",
       "      <td>0.639500</td>\n",
       "      <td>0.779826</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fine_tune(10, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.388720</td>\n",
       "      <td>0.948845</td>\n",
       "      <td>0.628500</td>\n",
       "      <td>0.784084</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.387256</td>\n",
       "      <td>0.855126</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.809998</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.406096</td>\n",
       "      <td>0.731548</td>\n",
       "      <td>0.702000</td>\n",
       "      <td>0.832674</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.388391</td>\n",
       "      <td>0.754718</td>\n",
       "      <td>0.709000</td>\n",
       "      <td>0.825888</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.377293</td>\n",
       "      <td>0.965443</td>\n",
       "      <td>0.631500</td>\n",
       "      <td>0.780380</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.379696</td>\n",
       "      <td>0.852561</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.808499</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.371715</td>\n",
       "      <td>0.936434</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>0.811397</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.363982</td>\n",
       "      <td>0.978866</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.790271</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.355349</td>\n",
       "      <td>0.910945</td>\n",
       "      <td>0.649000</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.349610</td>\n",
       "      <td>0.922885</td>\n",
       "      <td>0.643000</td>\n",
       "      <td>0.807917</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, lr_max = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/sim85roc.pth')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save('sim85roc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_t = learn.get_preds(ds_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "def get_roc(preds):\n",
    "    preds, y = preds\n",
    "    probs = F.softmax(preds, dim=1)[:,1]\n",
    "    \n",
    "    return sklearn.metrics.roc_auc_score(y, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "def show_by_idxs(img_idxs):\n",
    "    n,m = len(img_idxs)//2, 2\n",
    "    \n",
    "    _,axs = plt.subplots(n,m, figsize=(10*m,10*n))\n",
    "    for ax, idx in zip(axs.flatten(), img_idxs.view(-1)):\n",
    "        row = data.iloc[idx.item()]\n",
    "        img_path = HATE_IMAGES / row['img']\n",
    "        ax.imshow(PIL.Image.open(img_path))\n",
    "        ax.axis('off')\n",
    "        clr = 'red' if row['label']==1 else 'green'\n",
    "        txt = f'{row[\"id\"]}: {row[\"text\"][:20]}'\n",
    "        ax.set_title(txt, color=clr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learn.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = []\n",
    "for i in range(bs):\n",
    "    txt = data.text.iloc[i]\n",
    "    row_data = load_from_row(first_row, val_proc, tokenizer, txt)\n",
    "    batch.append(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([]),\n",
       " torch.Size([100, 2048]),\n",
       " torch.Size([100, 1607]),\n",
       " torch.Size([203]),\n",
       " torch.Size([203]),\n",
       " torch.Size([203, 203])]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in batch[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([50]),\n",
       " torch.Size([50, 100, 2048]),\n",
       " torch.Size([50, 100, 1607]),\n",
       " torch.Size([50, 203]),\n",
       " torch.Size([50, 203]),\n",
       " torch.Size([50, 203, 203])]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = fa_collate(batch)\n",
    "[x.shape for x in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-992ba9dfdf39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-78-992ba9dfdf39>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "b = tuple([x.cuda() for x in b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 6, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-7f63ecebe514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/vlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-a19cf90f642d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m      6\u001b[0m      \u001b[0;31m#def forward(self, id, vis_feats, vis_pe, input_ids, token_type_ids, attention_mask):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m      \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvis_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvis_pe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvis_pe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 6, got 0)"
     ]
    }
   ],
   "source": [
    "model(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlp",
   "language": "python",
   "name": "vlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
